{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance Validation and Model Interpretation - Chapter 03"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Learning Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* To understand and `interpret` the predictive model\n",
    "* We demystify the idea that ML/DL models are `black-boxes`\n",
    "* Instead that RForest actual gives us useful `insights` regarding the data\n",
    "* We will also consider a larger dataset this chapter, particulary with over `1million` rows\n",
    "* This is Kaggle competition for `grocery forecasting`\n",
    "* Look at a model called `collaborative filtering`\n",
    "* Also learn a bit of tweaking today\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Q) Question's been asked, how to choose ML models\n",
    "* A) For `unstructured` dataset, it is always good to use `deep learning` methods\n",
    "* S"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Dataset and Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "currDir = os.getcwd()\n",
    "os.chdir(\"../fastai/\")\n",
    "from structured import *       \n",
    "from imports import *\n",
    "os.chdir(currDir)\n",
    "# ____________________________________________________________ #\n",
    "from pandas_summary import DataFrameSummary\n",
    "from IPython.display import display\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn import metrics\n",
    "# ____________________________________________________________ #\n",
    "import math\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"../datasets/kaggle/corporcion_favorita_grocery_sales/\"\n",
    "# !dir \"../datasets/kaggle/corporcion_favorita_grocery_sales/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Information on The Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The `dependant` variable is the one you are trying to **PREDICT**\n",
    "* In this dataset you are trying to predict ... \"How many `UNITS` of each kind of product was sold in `EACH STORE` on each day during the `two-week period`\n",
    "* The info that you want to predict is the \"How many `UNITS` each project at each store, on each day were sold in the last few years and for each store, date, product there is a metadata\n",
    "* `Metadata` based on the store includes information for example\n",
    "    > where is the store located\n",
    "    > what class of store is it \n",
    "* Meta data on the product type can include\n",
    "    > what was the oil price on this date ?\n",
    "    > what was the overall sales likes from the point of view of competitors ?\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The grocery store dataset is a type of `Relational Dataset`\n",
    "* Meaning there are a number of different piece of information that we can `relate` together\n",
    "* This type of relational dataset is a type of `Star Schema`\n",
    "* A star schema is a kind of a `data warehousing` schema where we say there is some `central transaction`\n",
    "* You can think of this as star schema becaouse we can have a central transaction (i.e. the `train.csv`) and this branches out with different metadata based on targets such as `unit_sales`, `date`, `item_number` etc.\n",
    "* This is different to what is known as `Snowflake Schema`\n",
    "* Where there might be extra information available that may join targets across the central transaction\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Read and Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**STEP 1:**\n",
    "\n",
    "* Begin with some basicimporting of the data\n",
    "* When using `pd.read_csv` if you say `limit_memory=False`, then we will set to use as much as memory as we like\n",
    "* This helps with figuring out what kind of data it is with more introspection possible\n",
    "* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "types = {'id': 'int64',\n",
    "         'item_nbr': 'int32',\n",
    "         'store_nbr': 'int8',\n",
    "         'unit_sales': 'float32',\n",
    "         'onpromotion': 'object'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 59.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_all = pd.read_csv(\n",
    "    PATH+'train.csv', parse_dates=['date'], dtype=types, infer_datetime_format=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../datasets/kaggle/corporcion_favorita_grocery_sales/'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.15 ('airdmp')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d07b0008baf96b10859126fdec4e07f87ea8cd98c5be91794f454136925afeea"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
