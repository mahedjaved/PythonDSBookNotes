{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Actual coding begins at `17:39`\n",
    "* Updated version of this lesson available at :: https://www.kaggle.com/code/ailobe/fastai-ml1-lesson2-rf-interpretation/notebook\n",
    "* The command `git restore .` will remove any changes and allow fresh pull from repo"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Interpretation - Chapter 4"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Pre-Discussion"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `set_rf_samples` means how many of the samples are made from the tree\n",
    "* Before we start making trees we have two choiced\n",
    "    * Sample w replacement from the entire dataset\n",
    "    * Subsampling from the dataset \n",
    "* In the latter, the trees are made from only a small variation of the set \n",
    "* This is a trick oftenly done when dataset is very large\n",
    "* The subsamples are also sometimes called `bootstrap samples`\n",
    "\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* On `growth scale` of rf, consider the size to be $\\log_2 (set\\ rf\\ samples)$\n",
    "* The `no. of leaf nodes` is equal to the set_rf_samples\n",
    "* Hence there is a `linear relationship` between set_rf_samples and number of leaf nodes\n",
    "* So, in a sense, number of rf samples also decides the number of decisions made by the rf\n",
    "* Therefore, the RF is going to be `less rich` in what it can predict as it will make `less binary choices` \n",
    "* How this relates to overfitting ? --> basically having low rfsamples will mean `less chances` of `overfitting`\n",
    "* But it also means each of the individual tree in the forest will be `less accurate`\n",
    "\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Now looking in-depth what the idealogy about models with `bagging` is \n",
    "* You are trying to do two things:\n",
    "    * A) Each individual estimator is as accurate as possible $\\uparrow$ on the training set\n",
    "    * B) The correlation between the estimators is low as possible $\\downarrow$\n",
    "    * So when you `average them out` together you end up with `better generalization`\n",
    "* Hence, by setting set_rf_samples with a low number, you are decreasing the `A` factor and increasing the `B` factor\n",
    "\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Now what happens when you set `oob_score` to True\n",
    "* In this case, remind yourself that there is these `residual` rows that did'net get included in the training set after the `subsampling stage`\n",
    "* You can essentially construct a `quasi` validation set from this\n",
    "* Obviously if you do not prefer this, it is possible to use `reset_rf_samples()` which simply sets rfsamples to 0 and uses the entire dataset, you WONT be able to use `oob_score` anymore now!\n",
    "\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Nextup is `min_samples_leaf` , setting this from (for eg) from 1 to 2, means that the depth of the decision tree will be `subtracted by 1`\n",
    "* Because everytime we `double` the min_samples_leaf, we are removing `one layer` from the forest\n",
    "* And the number of leaves will be `halved` if min_samples_leaf is `doubled`\n",
    "* In this case, increasing min_samples_leaf will decrease `(A)` and increase `(B)` which `might` help us from `overfitting`\n",
    "* Ideal choices for min_samples_leaf can be: *1, 3, 5, 10, 25, 100*\n",
    "\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Finally, the `max_features` determines how much portion of the features are selected `per-split`\n",
    "* So if max_feautures = 0.5, then at each split, we take 0.5 of the features\n",
    "* This will `reduce` the `coorelation` between the individual trees and *MAY* help with overfitting \n",
    "* The trade-off is that each of the tree will be `less accurate`\n",
    "* Options you can have for `max_features` is :\n",
    "    > sqrt for allow the sqrt of features\n",
    "\n",
    "    > log2 to allow log2 of the number of features set\n",
    "    \n",
    "    > None means have all of them available at each split"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Libraries and Modules Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "currDir = os.getcwd()\n",
    "os.chdir(\"../fastai/\")\n",
    "from structured import *       \n",
    "from imports import *\n",
    "os.chdir(currDir)\n",
    "# ____________________________________________________________ #\n",
    "from pandas_summary import DataFrameSummary\n",
    "from IPython.display import display\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn import metrics\n",
    "# ____________________________________________________________ #\n",
    "import math\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH2DATA = \"../datasets/kaggle/bluebook_bulldozers/\"\n",
    "# !dir \"../datasets/kaggle/corporcion_favorita_grocery_sales/\"\n",
    "\n",
    "# below is just the param to control different features in a graph plot\n",
    "set_plot_sizes(12, 14, 16)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Load dataset and Pre-Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw = pd.read_csv(f'{PATH2DATA}Train.csv',\n",
    "                     low_memory=False, parse_dates=[\"saledate\"])\n",
    "\n",
    "# convert the columns to log\n",
    "df_raw.SalePrice = np.log(df_raw.SalePrice)\n",
    "\n",
    "# extract timeOfDay, timeOfMonth etc from time and date\n",
    "add_datepart(df_raw, 'saledate')\n",
    "\n",
    "# categorical to numeric - partly\n",
    "train_cats(df_raw)\n",
    "df_raw.UsageBand.cat.set_categories(\n",
    "    [\"High\", \"Medium\", \"Low\"], ordered=True, inplace=True)\n",
    "\n",
    "# use proc_df to quantify string columns\n",
    "df_train, y_train, _ = proc_df(df_raw, 'SalePrice')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_vals(a, n):\n",
    "    \"\"\"\n",
    "    a: number of samples (i.e. the entire dataset)\n",
    "    n: number of training set to split\n",
    "    \"\"\"\n",
    "    # a[:n] will retrieve the first (N - n_valid) rows for TRAINING set\n",
    "    # a[n:] will retirve the last (N - n_valid) rows got VALIDATION set\n",
    "    return a[:n].copy(), a[n:].copy()\n",
    "\n",
    "n_valid = 12000\n",
    "\n",
    "# the number of training sets will be len(df) - n_valid\n",
    "n_trn = len(df_train) - n_valid\n",
    "\n",
    "# now split the entire dataset into training and validation\n",
    "raw_train, raw_valid = split_vals(df_raw, n_trn)\n",
    "\n",
    "# before were raw, now get the real ones based on pre-processed version\n",
    "X_train, X_valid = split_vals(df_train, n_trn)\n",
    "y_train, y_valid = split_vals(y_train, n_trn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (389125, 66), y_train shape : (389125,),  x_valid shape : (12000, 66)\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train shape: {}, y_train shape : {},  x_valid shape : {}\".format(X_train.shape, y_train.shape, X_valid.shape, y_valid.shape))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.0. Model Setup and Initial Run"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. Some pre-defined functions for output and visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that will take the RMSE\n",
    "def rmse(pred, known):\n",
    "    return np.sqrt(((pred-known)**2).mean())\n",
    "\n",
    "# function to round ans. to 5dp like Kaggle leaderboard answers\n",
    "\n",
    "\n",
    "def rounded(value):\n",
    "    return np.round(value, 5)\n",
    "\n",
    "# function to return the rmse scores and R^2 values for train and validation set\n",
    "\n",
    "\n",
    "def print_scores(model):\n",
    "    RMSE_train = rmse(model.predict(X_train), y_train)\n",
    "    RMSE_valid = rmse(model.predict(X_valid), y_valid)\n",
    "    R2_train = model.score(X_train, y_train)\n",
    "    R2_valid = model.score(X_valid, y_valid)\n",
    "\n",
    "    # list the scores and check if oob_score is present\n",
    "    scores = [rounded(RMSE_train), rounded(RMSE_valid),\n",
    "              rounded(R2_train), rounded(R2_valid)]\n",
    "    if hasattr(model, 'oob_score_'):\n",
    "        scores.append(model.oob_score_)\n",
    "    print(scores)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2. Subsampling"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Interpretation of the model has less to do with getting the `best accuracy` and more into the `insights` regarding the data\n",
    "* In other words, how are the features within the data `correlated`\n",
    "* For this to be tested, the model must first be `reliable`\n",
    "* But also, when subsampling we need to make sure the subsample is `large enough` so that the model is reliable\n",
    "* For this example we use about 50000 samples\n",
    "* Recall that `oob_score=True` is only used when dataset is big enough to allow four split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_rf_samples(50000)\n",
    "\n",
    "# first run of the model\n",
    "model1st = RandomForestRegressor(n_estimators=40, min_samples_leaf=3, max_features=0.5,\n",
    "                                 n_jobs=2, oob_score=True, random_state=17190)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "<lambda>() takes 2 positional arguments but 3 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<timed eval>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ksfma\\miniconda3\\envs\\airdmp\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    465\u001b[0m                     \u001b[0mn_samples_bootstrap\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_samples_bootstrap\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    466\u001b[0m                 )\n\u001b[1;32m--> 467\u001b[1;33m                 \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrees\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    468\u001b[0m             )\n\u001b[0;32m    469\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ksfma\\miniconda3\\envs\\airdmp\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1096\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1097\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1098\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1099\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1100\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ksfma\\miniconda3\\envs\\airdmp\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    973\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    974\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 975\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    976\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    977\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ksfma\\miniconda3\\envs\\airdmp\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    655\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    656\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 657\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    658\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    659\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_set\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ksfma\\miniconda3\\envs\\airdmp\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mworker\u001b[1;34m(inqueue, outqueue, initializer, initargs, maxtasks, wrap_exception)\u001b[0m\n\u001b[0;32m    119\u001b[0m         \u001b[0mjob\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtask\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 121\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    122\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mwrap_exception\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfunc\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0m_helper_reraises_exception\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ksfma\\miniconda3\\envs\\airdmp\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    618\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    619\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 620\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    621\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    622\u001b[0m             \u001b[1;31m# We capture the KeyboardInterrupt and reraise it as\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ksfma\\miniconda3\\envs\\airdmp\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    287\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    288\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 289\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    290\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    291\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ksfma\\miniconda3\\envs\\airdmp\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    287\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    288\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 289\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    290\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    291\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ksfma\\miniconda3\\envs\\airdmp\\lib\\site-packages\\sklearn\\utils\\fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    214\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    215\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 216\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    217\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    218\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ksfma\\miniconda3\\envs\\airdmp\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36m_parallel_build_trees\u001b[1;34m(tree, forest, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[0;32m    171\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    172\u001b[0m         indices = _generate_sample_indices(\n\u001b[1;32m--> 173\u001b[1;33m             \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_samples_bootstrap\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    174\u001b[0m         )\n\u001b[0;32m    175\u001b[0m         \u001b[0msample_counts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbincount\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mminlength\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: <lambda>() takes 2 positional arguments but 3 were given"
     ]
    }
   ],
   "source": [
    "# fit the model and measure time taken\n",
    "%time model1st.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "airdmp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d07b0008baf96b10859126fdec4e07f87ea8cd98c5be91794f454136925afeea"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
